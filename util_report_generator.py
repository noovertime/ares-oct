# ARES ë³´ê³ ì„œ ìƒì„±
from __future__ import annotations

import json
import math
import os
import time
from typing import Dict, List, Any, Optional

import numpy as np
from numpy.typing import NDArray
from scipy.stats import norm

import config
from config import KEY_CR, KEY_AF, KEY_AR, JUDGE_TYPES

# ===================================================================
# ìƒìˆ˜
# ===================================================================

CI_ALPHA: float = 0.05  # 95% ì‹ ë¢°êµ¬ê°„
CI_Z_SCORE: float = float(norm.ppf(1 - CI_ALPHA / 2))  # ì•½ 1.96


# ===================================================================
# ë‚´ë¶€ ìœ í‹¸ í•¨ìˆ˜
# ===================================================================

def _load_json_lines(filepath: str) -> List[Dict[str, Any]]:
    """JSONL íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œí•œë‹¤."""
    lines: List[Dict[str, Any]] = []
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    data: Dict[str, Any] = json.loads(line)
                    lines.append(data)
                except json.JSONDecodeError:
                    continue
    except FileNotFoundError:
        return []
    return lines


def _safe_parse_label(value: Any) -> Optional[int]:
    """0 ë˜ëŠ” 1ì˜ ìœ íš¨í•œ ì •ìˆ˜ë§Œ ë°˜í™˜."""
    try:
        label = int(value)
        if label in (0, 1):
            return label
    except (ValueError, TypeError):
        pass
    return None


def _init_score_dict() -> Dict[str, List[Any]]:
    """ê° ì¶•ë³„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”."""
    return {KEY_CR: [], KEY_AF: [], KEY_AR: []}


# ===================================================================
# í†µê³„ ê³„ì‚°
# ===================================================================

def calculate_ppi_asymptotic_ci(
        machine_preds: List[int],
        rectifiers: List[float],
        total_n: int,
        labeled_n: int
) -> float:
    """PPI Asymptotic CI Half-width ê³„ì‚°."""
    if labeled_n <= 1 or total_n <= 0:
        return 0.0

    y_hat_array: NDArray[np.float64] = np.array(machine_preds, dtype=np.float64)
    rectifier_array: NDArray[np.float64] = np.array(rectifiers, dtype=np.float64)

    sigma2_f: float = float(np.var(y_hat_array))
    sigma2_rec: float = float(np.var(rectifier_array))

    variance: float = (sigma2_f / float(total_n)) + (sigma2_rec / float(labeled_n))
    half_width: float = CI_Z_SCORE * math.sqrt(variance)
    return round(half_width, 3)


# ===================================================================
# PPI íŒŒì¼ ë¶„ì„
# ===================================================================

def analyze_ppi_file(
        filepath: str,
        ppi_correction_active: bool,
        gold_fields: Dict[str, str]
) -> Optional[Dict[str, Any]]:
    """ë‹¨ì¼ PPI íŒŒì¼ì„ ë¶„ì„í•˜ê³  ìš”ì•½ ê²°ê³¼ë¥¼ ë°˜í™˜."""
    if not ppi_correction_active:
        raise RuntimeError("PPI ë³´ì •ì„ ìœ„í•œ ê³¨ë“  ë¼ë²¨ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    records: List[Dict[str, Any]] = _load_json_lines(filepath)
    if not records:
        return None

    all_scores: Dict[str, List[int]] = _init_score_dict()  # type: ignore
    rectifier_terms: Dict[str, List[float]] = _init_score_dict()  # type: ignore
    gold_label_counts: Dict[str, int] = {k: 0 for k in JUDGE_TYPES}

    model_name_raw: str = os.path.basename(filepath)
    #name_parts: List[str] = model_name_raw.split('_')
    #model_name: str = "_".join(name_parts[:-1]).split(".jsonl")[0] or model_name_raw.split(".jsonl")[0]
    model_name: str = model_name_raw.replace(".jsonl", "")

    for data in records:
        for key in JUDGE_TYPES:
            if key in data:
                value = data[key]
                if isinstance(value, (int, float)):
                    all_scores[key].append(int(value))

        for machine_key, gold_key in gold_fields.items():
            machine_pred: Optional[int] = _safe_parse_label(data.get(machine_key))
            gold_label: Optional[int] = _safe_parse_label(data.get(gold_key))

            if machine_pred is None or gold_label is None:
                continue

            rectifier_terms[machine_key].append(float(machine_pred - gold_label))
            gold_label_counts[machine_key] += 1

    total_n: int = len(all_scores[KEY_CR])
    if total_n == 0:
        return None

    summary: Dict[str, Any] = {
        "model_name": model_name,
        "n": total_n,
        "ppi_active": ppi_correction_active,
        "labeled_n_rep": gold_label_counts[KEY_CR],
    }

    overall_corrected_scores: List[float] = []

    for axis in JUDGE_TYPES:
        scores: List[int] = all_scores[axis]
        if not scores:
            continue

        machine_mean: float = sum(scores) / float(total_n)
        labeled_n_axis: int = gold_label_counts[axis]
        rectifier: float = (
            sum(rectifier_terms[axis]) / labeled_n_axis if labeled_n_axis > 0 else 0.0
        )
        corrected_mean: float = max(0.0, min(1.0, machine_mean - rectifier))

        # CI ê³„ì‚° ì½”ë“œ ìœ ì§€ (ì¶œë ¥ì€ ì œì™¸)
        margin: float = calculate_ppi_asymptotic_ci(scores, rectifier_terms[axis], total_n, labeled_n_axis)

        summary[axis] = {
            "machine_mean": round(machine_mean, 2),
            "corrected_mean": round(corrected_mean, 2),
            "applied_rectifier": round(rectifier, 3),
            "ci": round(margin, 3)
        }
        overall_corrected_scores.append(corrected_mean)

    if not overall_corrected_scores:
        return None

    summary["overall"] = round(sum(overall_corrected_scores) / len(overall_corrected_scores), 2)
    return summary


# ===================================================================
# ë³´ê³ ì„œ ìƒì„± (ìˆ˜ì •ë¨)
# ===================================================================

def generate_summary_report(model_summaries: List[Dict[str, Any]]) -> str:
    """Markdown í˜•ì‹ ë³´ê³ ì„œ ìƒì„± (ìš”ì²­ëœ ë§ˆí¬ë‹¤ìš´/HTML í…Œì´ë¸” í˜•ì‹ ì ìš©)."""
    if not model_summaries:
        return "[WARN] ë¶„ì„í•  ëª¨ë¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    # 'overall' ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    model_summaries.sort(key=lambda x: float(x["overall"]), reverse=True)
    current_time: str = time.strftime("%Y-%m-%d %H:%M:%S")
    # ëª¨ë“  ëª¨ë¸ì´ ë™ì¼í•œ ê³¨ë“ ì…‹ì„ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •í•˜ê³  ì²« ë²ˆì§¸ ëª¨ë¸ì˜ labeled_n_rep ì‚¬ìš©
    total_golden_set_count: int = int(model_summaries[0]["labeled_n_rep"])
    model_list: str = "\n".join([f"   - {m['model_name']}" for m in model_summaries])

    # -------------------------------------------------------------
    # 1. ë³´ê³ ì„œ ê¸°ë³¸ ì •ë³´ ì„¹ì…˜
    # -------------------------------------------------------------
    report_content: str = f"""
## ğŸ§­ ARES ê²°ê³¼ ë³´ê³ ì„œ
í‰ê°€ ì¼ì: {current_time}

--- 
### 1ï¸âƒ£ í”„ë¡œì íŠ¸ ê°œìš” 
- í”„ë¡œì íŠ¸ëª…: ARES ì‹¬ì‚¬ê´€ ë¡œì»¬ ë°°ì¹˜ í‰ê°€
- í‰ê°€ í”„ë ˆì„ì›Œí¬: Stanford ARES (ê³¨ë“ ì…‹ ê¸°ë°˜ PPI ë³´ì • ë¡œì§ í†µí•©)
- í‰ê°€ ëŒ€ìƒ : (q, c, a) íŠ¸ë¦¬í”Œ ì…‹ìœ¼ë¡œ êµ¬ì„± <br>
{model_list}
- ê³¨ë“ ì…‹ ìœ íš¨ ê°œìˆ˜ (n) : {total_golden_set_count}

--- 
### 2ï¸âƒ£ í‰ê°€ 
- Context Relevance (CR, ë¬¸ë§¥ ì í•©ì„±) : ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ ìˆëŠ”ê°€
- Answer Faithfulness (AF, ì‘ë‹µ ì¶©ì‹¤ë„) : ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ ë¬¸ì„œ ë‚´ìš©ì— ì¶©ì‹¤í•œê°€ 
- Answer Relevance (AR, ì‘ë‹µ ì ì ˆì„±) : ë‹µë³€ì´ ì§ˆë¬¸ì— ì§ì ‘ì ì´ê³  êµ¬ì²´ì ì¸ê°€

--- 
### 3ï¸âƒ£ PPI ì¶”ì • ì„±ëŠ¥ ì ìˆ˜
#### ğŸ¯ ì„±ëŠ¥ì ìˆ˜ ìš”ì•½ 

| ìˆœë²ˆ | í‰ê°€ëŒ€ìƒ | ì¢…í•© ì ìˆ˜ | CR(ë³´ì •) | AF(ë³´ì •) | AR(ë³´ì •)|
|:--|:---:|:---:|:---:|:---:|:---:|
"""
    # -------------------------------------------------------------
    # 2. ìš”ì•½ í…Œì´ë¸” (ë§ˆí¬ë‹¤ìš´)
    # -------------------------------------------------------------
    for i, summary in enumerate(model_summaries):
        report_content += (
            f"| {i + 1} "
            f"| {summary['model_name']} "
            f"| {summary['overall']:.2f} "
            f"| {summary[KEY_CR]['corrected_mean']:.2f} "
            f"| {summary[KEY_AF]['corrected_mean']:.2f} "
            f"| {summary[KEY_AR]['corrected_mean']:.2f} |\n"
        )

    report_content += """
    ğŸ“ ì˜ë¯¸ ìš”ì•½ 
    * ì¢…í•©ì ìˆ˜ : í‰ê°€ ëŒ€ìƒ ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ì„±ëŠ¥ ì¶”ì •ì¹˜ 
    * CR/AR/AF(ë³´ì •) : ë¬¸ë§¥ ì í•©ì„±(CR), ì‘ë‹µ ì¶©ì‹¤ë„(AF), ì‘ë‹µ ì ì ˆì„±(AR) ì„±ëŠ¥ ì¶”ì •ì¹˜


<br>

#### ğŸ¯ ì„±ëŠ¥ ì ìˆ˜ ì„¸ë¶€ í•­ëª© ê°’\n
    """

    report_content += """
<table>
  <thead>
    <tr>
        <td rowspan="2">ìˆœë²ˆ</td>
        <td rowspan="2">í‰ê°€ëŒ€ìƒ</td>
        <td colspan="3" align="center">CR</td>
        <td colspan="3" align="center">AF</td>
        <td colspan="3" align="center">AR</td>
        <td rowspan="2">ì‹¬ì‚¬ê´€ ì˜ˆì¸¡ í‰ê· </td>
        <td rowspan="2">ì´ ìƒ˜í”Œ ìˆ˜</td>
    </tr>
    <tr>
        <td>ë³´ì •</td>
        <td>í¸í–¥</td>
        <td>CI</td>
        <td>ë³´ì •</td>
        <td>í¸í–¥</td>
        <td>CI</td>
        <td>ë³´ì •</td>
        <td>í¸í–¥</td>
        <td>CI</td>
    </tr>
  </thead>
  <tbody>
"""
    # -------------------------------------------------------------
    # 3. ì„¸ë¶€ë‚´ìš© í…Œì´ë¸” (HTML)
    # -------------------------------------------------------------
    for i, summary in enumerate(model_summaries):
        cr = summary[KEY_CR]
        af = summary[KEY_AF]
        ar = summary[KEY_AR]

        # ëª¨ë¸ì˜ ëª¨ë“  ê¸°ê³„ ì˜ˆì¸¡ í‰ê·  (CR ì¶•ì˜ machine_mean ì‚¬ìš©)
        model_machine_mean: float = cr['machine_mean']

        report_content += "    <tr>\n"
        report_content += f"        <td>{i + 1}</td>\n"
        report_content += f"        <td>{summary['model_name']}</td>\n"

        # CR
        report_content += f"        <td>{cr['corrected_mean']:.2f}</td>\n"
        report_content += f"        <td>{cr['applied_rectifier']:.3f}</td>\n"
        report_content += f"        <td>{cr['ci']:.2f}</td>\n"

        # AF
        report_content += f"        <td>{af['corrected_mean']:.2f}</td>\n"
        report_content += f"        <td>{af['applied_rectifier']:.3f}</td>\n"
        report_content += f"        <td>{af['ci']:.2f}</td>\n"

        # AR
        report_content += f"        <td>{ar['corrected_mean']:.2f}</td>\n"
        report_content += f"        <td>{ar['applied_rectifier']:.3f}</td>\n"
        report_content += f"        <td>{ar['ci']:.2f}</td>\n"

        # ëª¨ë¸ ì˜ˆì¸¡ ë° ìƒ˜í”Œ ìˆ˜
        report_content += f"        <td>{model_machine_mean:.2f}</td>\n"
        report_content += f"        <td>{summary['n']}</td>\n"
        report_content += "    </tr>\n"

    report_content += """
  </tbody>
</table>


    ğŸ“ ì˜ë¯¸ ìš”ì•½ 
    * CR/AR/AF(ë³´ì •) : ë¬¸ë§¥ ì í•©ì„±(CR), ì‘ë‹µ ì¶©ì‹¤ë„(AF), ì‘ë‹µ ì ì ˆì„±(AR) ì„±ëŠ¥ ì¶”ì •ì¹˜ ( 0 ~ 1 : ìµœê³ ì  ) 
    * í¸í–¥ : ARES ì‹¬ì‚¬ê´€ì˜ ì˜ˆì¸¡ê³¼ ê³¨ë“ ë¼ë²¨ì˜ í‰ê·  ì°¨ì´ ( ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ )
    * CI : CR/AR/AF(ë³´ì •) ê°’ì˜ ì‹ ë¢°êµ¬ê°„ ( ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ )
    * ì‹¬ì‚¬ê´€ ì˜ˆì¸¡í‰ê·  : ARES ì‹¬ì‚¬ê´€ì´ ë¶€ì—¬í•œ í‰ê·  ì ìˆ˜ 
    * ì´ ìƒ˜í”Œ ìˆ˜ : í‰ê°€ì— ì‚¬ìš©ëœ Q-C-A íŠ¸ë¦¬í”Œì˜ ì „ì²´ ê°œìˆ˜

---
### 4ï¸âƒ£ PPI ë³´ì • ì˜ë¯¸ 
* PPI(Prediction-Powered Inference) ì—­í•  
  * PPIëŠ” ARES ì‹¬ì‚¬ê´€ ëª¨ë¸($\hat{Y}$)ì˜ ì˜ˆì¸¡ í¸í–¥ì„ ì œê±°í•˜ì—¬ í‰ê°€ ê²°ê³¼ì˜ ì‹ ë¢°ë„ì™€ í†µê³„ì  íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë°©ë²•ë¡  
  * íš¨ìœ¨ì„± ê²°í•© 
    * ARES ì‹¬ì‚¬ê´€ì´ ìˆ˜í–‰í•œ ëŒ€ê·œëª¨ ì˜ˆì¸¡ ($\hat{Y}$)ì˜ ì •ë³´ë ¥ê³¼ ê³ ë¹„ìš©ìœ¼ë¡œ ì–»ì€ ì†Œê·œëª¨ ê³¨ë“ ì…‹ ($Y$)ì˜ ì •í™•ì„±ì„ ê²°í•© 
  * í¸í–¥ê³„ì‚° (Rectifier)
    * ì†Œìˆ˜ì˜ ê³¨ë“ ì…‹ì—ì„œ ì‹¬ì‚¬ê´€ ì˜ˆì¸¡ê³¼ ê³¨ë“ ë¼ë²¨ì˜ í‰ê·  ì°¨ì´ë¥¼ ê³„ì‚°í•´ í¸í–¥ ìˆ˜ì •ìë¡œ ì‚¬ìš©
* PPI ë³´ì • ê°’ì˜ ì˜ë¯¸ 
  * PPI ë³´ì • ê°’ì€ PPI ë°©ë²•ë¡ ì„ í†µí•´ ì‚°ì¶œëœ ëª¨ë¸ì˜ ì„±ëŠ¥ ì¶”ì •ì¹˜ 
  * ì°¸ëœ ì„±ëŠ¥ ì¶”ì • (true performance)
    * ARES ì‹¬ì‚¬ê´€ì˜ ì˜ˆì¸¡ ì ìˆ˜ì—ì„œ ê³¨ë“ ì…‹ ê¸°ë°˜ì˜ í¸í–¥ì´ ì œê±°ëœ ëª¨ë¸ì˜ ì°¸ëœ ì„±ëŠ¥ì„ ì‹ ë¢°í•  ìˆ˜ ìˆê²Œ ì¶”ì •í•œ ê°’ 
  * ê³„ì‚°ê³µì‹ 
    * ë³´ì •ê°’ = ARES ì‹¬ì‚¬ê´€ ëª¨ë¸ ì˜ˆì¸¡í‰ê·  - í¸í–¥ 
  * ë³´ê³ ì„œ í‘œì‹œ
      * CR(ë³´ì •), AF(ë³´ì •), AR(ë³´ì •) ê°’ì— í•´ë‹¹ 
* ë³´ê³ ì„œ ê°’ì˜ ì˜ë¯¸ ìƒì„¸
  * $\text{ì¢…í•© ì ìˆ˜} = \frac{\text{CR}(\text{ë³´ì •}) + \text{AF}(\text{ë³´ì •}) + \text{AR}(\text{ë³´ì •})}{3}$
  * ë³´ì • : ì˜ˆì¸¡ê°’ì—ì„œ í¸í–¥ì„ ì œê±°í•œ ì„±ëŠ¥ ì¶”ì •ì¹˜ 
  * í¸í–¥ : ê³¨ë“ ì…‹ê³¼ ì‹¬ì‚¬ê´€ ì˜ˆì¸¡ ì‚¬ì´ì˜ ê²©ì°¨ ( -1 ~ 1 ì´ìƒ )
  * CI (Confidence Interval, ì‹ ë¢°êµ¬ê°„)
    * PPI ë³´ì • ê°’(CRë³´ì •, AFë³´ì •, ARë³´ì •)ì˜ ì‹ ë¢°ë„ì™€ ì •ë°€ë„ë¥¼ ë‚˜íƒ€ëƒ„ 
    * ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¶”ì •ëœ ë³´ì •ê°’ì— ëŒ€í•œ ì˜¤ì°¨ ë²”ìœ„ê°€ ì¢ì•„ì ¸ ì‹ ë¢°ë„ê°€ ë†’ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸ 
  * ì‹¬ì‚¬ê´€ì˜ˆì¸¡ì ìˆ˜ 
    * CR/AF/AR í•­ëª©ì„ í‰ê°€í•œ ì ìˆ˜ì˜ í‰ê· 
    * PPI ë³´ì •ì˜ ì…ë ¥ê°’ì´ë©° í¸í–¥ì´ í¬í•¨ë˜ì–´ ìˆì–´ ì´ ê°’ë§Œìœ¼ë¡œëŠ” ëª¨ë¸ ì„±ëŠ¥ì„ ëŒ€í‘œí•˜ì§€ ì•ŠìŒ
    * ë³´ì •ì„ ê±°ì¹œ í›„ì— CR/AF/AR ë³´ì •ê°’ìœ¼ë¡œ í‘œí˜„ë¨ 
"""
    return report_content


# ===================================================================
# ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
# ===================================================================

def run_summary_generation_pipeline(
        ppi_correction_active: bool,
        gold_fields: Dict[str, str]
) -> None:
    """ë³´ê³ ì„œ ìƒì„± íŒŒì´í”„ë¼ì¸."""
    if not ppi_correction_active:
        raise RuntimeError("PPI ë³´ì •ì„ ìœ„í•œ ê³¨ë“  ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤.")

    ppi_dir: str = config.DATA_OUT_DIR
    report_dir: str = config.DATA_REPORT_DIR
    os.makedirs(report_dir, exist_ok=True)

    ppi_files: List[str] = [
        os.path.join(ppi_dir, f)
        for f in os.listdir(ppi_dir)
        if f.endswith(".jsonl") and "_" in f
    ]
    if not ppi_files:
        print(f"[WARN] {ppi_dir}ì— ë¶„ì„í•  PPI íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"[INFO] ì´ {len(ppi_files)}ê°œ ëª¨ë¸ ë¶„ì„ ì¤‘...")

    model_summaries: List[Dict[str, Any]] = []

    for path in ppi_files:
        try:
            summary = analyze_ppi_file(path, True, gold_fields)
            if summary:
                model_summaries.append(summary)
                print(f"   [OK] '{summary['model_name']}' ì™„ë£Œ.")
        except Exception as e:
            print(f"   [ERROR] '{os.path.basename(path)}' ë¶„ì„ ì‹¤íŒ¨: {e}")

    if not model_summaries:
        print("[WARN] ë¶„ì„ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    report_content: str = generate_summary_report(model_summaries)
    timestamp: str = time.strftime("%Y%m%d_%H%M%S")
    output_path: str = os.path.join(report_dir, f"summary_{timestamp}.md")

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(report_content)

    print(f"\n[ì™„ë£Œ] ARES í†µê³„ ë³´ê³ ì„œ ìƒì„±ë¨ â†’ {output_path}")