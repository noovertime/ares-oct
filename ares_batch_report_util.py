# ares_batch_report_util.py (ìƒìˆ˜ ì œê±° ë° config import ë²„ì „)

import os
import json
import time
import math
import numpy as np
from typing import Dict, List, Any, Tuple
from scipy.stats import norm
from scipy.optimize import brentq

import config
# ğŸš¨ í•µì‹¬ ìˆ˜ì •: config.pyì—ì„œ í•„ìš”í•œ ìƒìˆ˜ë¥¼ ì§ì ‘ import
from config import (
    KEY_CR,
    KEY_AF,
    KEY_AR,
    JUDGE_TYPES,
    GOLD_LABEL_FIELDS
)

# ===================================================================
# 0. ì „ì—­ ìƒìˆ˜
# ===================================================================

CI_ALPHA = 0.05  # 95% ì‹ ë¢°êµ¬ê°„ (alpha=0.05)
CI_Z_SCORE = norm.ppf(1 - CI_ALPHA / 2)  # Z-score: ì•½ 1.96


# ===================================================================
# 1. í†µê³„ ê³„ì‚° ìœ í‹¸ë¦¬í‹°
# ===================================================================

def calculate_ppi_asymptotic_ci(machine_preds: List[int], rectifiers: List[float], total_n: int,
                                labeled_n: int) -> float:
    """
    PPI Asymptotic CI Half-width (ë°˜í­)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """

    if labeled_n <= 1:
        # CI ê³„ì‚°ì„ ìœ„í•œ ìƒ˜í”Œ ìˆ˜ê°€ ë¶€ì¡±í•œ ê²½ìš°
        return 0.0

    y_hat_array = np.array(machine_preds)
    rectifier_array = np.array(rectifiers)

    sigma2_f = np.var(y_hat_array)
    sigma2_rec = np.var(rectifier_array)

    # PPI Asymptotic CI Variance ê³µì‹ ì ìš©
    variance = (sigma2_f / total_n) + (sigma2_rec / labeled_n)

    half_width = CI_Z_SCORE * math.sqrt(variance)

    return round(half_width, 3)


def analyze_ppi_file(filepath: str, ppi_correction_active: bool,
                     gold_fields: Dict[str, str]) -> Dict[str, Any]:
    """
    ë‹¨ì¼ PPI íŒŒì¼ì„ ì½ì–´ PPI ë³´ì • í‰ê·  ë° ì¶•ë³„ í¸í–¥ì„ ê³„ì‚°í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤.
    """
    if not ppi_correction_active:
        raise RuntimeError("PPI ë³´ì •ì„ ìœ„í•œ ê³¨ë“  ë¼ë²¨ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    model_name_raw = os.path.basename(filepath)
    all_scores: Dict[str, List[int]] = {
        KEY_CR: [],
        KEY_AF: [],
        KEY_AR: []
    }

    rectifier_terms: Dict[str, List[float]] = {KEY_CR: [], KEY_AF: [], KEY_AR: []}
    gold_label_counts: Dict[str, int] = {KEY_CR: 0, KEY_AF: 0, KEY_AR: 0}

    model_name_parts = model_name_raw.split('_')
    # íŒŒì¼ ì´ë¦„ì—ì„œ í™•ì¥ì ë° ì‹œê°„ ë¶€ë¶„ì„ ì œê±°í•˜ê³  ëª¨ë¸ ì´ë¦„ ì¶”ì¶œ
    model_name = "_".join(model_name_parts[:-1]).split(".jsonl")[0]
    if not model_name or len(model_name_parts) < 2:
        model_name = model_name_raw.split(".jsonl")[0]

    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())

                    # ê¸°ê³„ ì˜ˆì¸¡ ì ìˆ˜ ìˆ˜ì§‘
                    for key in JUDGE_TYPES:
                        if key in data:
                            all_scores[key].append(data[key])

                    # Rectifier Term ê³„ì‚°ì„ ìœ„í•œ ê³¨ë“  ë¼ë²¨ ì¶”ì¶œ ë° ê²€ì¦
                    for machine_key, gold_key in gold_fields.items():
                        machine_pred = data.get(machine_key)
                        gold_label_raw = data.get(gold_key)

                        try:
                            gold_label = int(gold_label_raw)
                        except (ValueError, TypeError):
                            continue

                            # Rectifier Term ê³„ì‚° (ìœ íš¨í•œ [0, 1] ê°’ì¸ ê²½ìš°ë§Œ)
                        if gold_label in [0, 1] and machine_pred in [0, 1]:
                            rectifier_terms[machine_key].append(machine_pred - gold_label)
                            gold_label_counts[machine_key] += 1

                except json.JSONDecodeError:
                    continue
    except FileNotFoundError:
        return None

    total_n = len(all_scores[KEY_CR])
    if total_n == 0:
        return None


    summary = {
        'model_name': model_name,
        'n': total_n,
        'ppi_active': ppi_correction_active,
        'labeled_n_rep':  gold_label_counts[KEY_CR] # ëŒ€í‘œ ê³¨ë“ ì…‹ ê°œìˆ˜ëŠ” CR ì¶•ì„ ê¸°ì¤€ìœ¼ë¡œ
    }

    overall_corrected_scores = []

    # CR, AF, AR ì„¸ ê°€ì§€ ì¶•ì— ëŒ€í•´ ë°˜ë³µ
    for axis in JUDGE_TYPES:
        scores = all_scores.get(axis, [])
        if not scores:
            continue

        # 1. ê¸°ê³„ ì˜ˆì¸¡ í‰ê·  (tilde_theta_f)
        machine_mean = sum(scores) / total_n

        # 2. Rectifier Mean (ì‹¤ì œ í¸í–¥) ê³„ì‚°: E[Y_hat - Y]
        labeled_n_for_axis = gold_label_counts[axis]

        if rectifier_terms[axis] and labeled_n_for_axis > 0:
            rectifier = sum(rectifier_terms[axis]) / labeled_n_for_axis
        else:
            rectifier = 0.0

            # 3. PPI ë³´ì • í‰ê·  (theta_hat_PP = machine_mean - rectifier)
        corrected_mean = max(0.0, min(1.0, machine_mean - rectifier))

        # 4. CI ë§ˆì§„ ê³„ì‚° (CIëŠ” ì¶œë ¥ë˜ì§€ ì•Šì§€ë§Œ, ê³„ì‚° ì½”ë“œëŠ” ìœ ì§€)
        # if labeled_n_for_axis <= 1:
        #    margin = 0.0
        # else:
        #    margin = calculate_ppi_asymptotic_ci(scores, rectifier_terms[axis], total_n, labeled_n_for_axis)

        # ê²°ê³¼ ì €ì¥
        summary[axis] = {
            'machine_mean': round(machine_mean, 2),
            'corrected_mean': round(corrected_mean, 2),
            'applied_rectifier': round(rectifier, 3)  # ê° ì¶•ì˜ í¸í–¥ì„ ê°œë³„ì ìœ¼ë¡œ ì €ì¥
            # 'ci': round(margin, 3)
        }
        overall_corrected_scores.append(corrected_mean)

    summary['overall'] = round(sum(overall_corrected_scores) / len(overall_corrected_scores), 2)

    return summary


def generate_summary_report(model_summaries: List[Dict[str, Any]]):
    """
    ë¶„ì„ëœ ëª¨ë¸ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… Markdown í˜•ì‹ì˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ì¶•ë³„ í¸í–¥ ì¶œë ¥)
    """

    if not model_summaries:
        return "[WARN] ë¶„ì„í•  ëª¨ë¸ ë°ì´í„°ê°€ ì—†ì–´ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    current_time = time.strftime("%Y-%m-%d %H:%M:%S")

    # ì¢…í•© ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    model_summaries.sort(key=lambda x: x['overall'], reverse=True)

    # ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    model_list_markdown = ""
    for summary in model_summaries:
        model_list_markdown += f"\n   - {summary['model_name']}\n"

    # ê³¨ë“ ì…‹ ê°¯ìˆ˜
    total_golden_set_count = model_summaries[0]['labeled_n_rep']

    report_content = f"""
## ğŸ§­ ARES ê²°ê³¼ ë³´ê³ ì„œ
í‰ê°€ ì¼ì: {current_time}

--- 
### 1ï¸âƒ£ í”„ë¡œì íŠ¸ ê°œìš” 
- í”„ë¡œì íŠ¸ëª…: ARES ì‹¬ì‚¬ê´€ ë¡œì»¬ ë°°ì¹˜ í‰ê°€
- í‰ê°€ í”„ë ˆì„ì›Œí¬: Stanford ARES (ê³¨ë“ ì…‹ ê¸°ë°˜ PPI ë³´ì • ë¡œì§ í†µí•©)
- í‰ê°€ ëŒ€ìƒ : (q, c, a) íŠ¸ë¦¬í”Œ ì…‹ìœ¼ë¡œ êµ¬ì„± {model_list_markdown}
- ê³¨ë“ ì…‹ ìœ íš¨ ê°œìˆ˜ (n) : {total_golden_set_count}

---
### 2ï¸âƒ£ í‰ê°€ 
- Context Relevance (CR, ë¬¸ë§¥ ì í•©ì„±) : ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ ìˆëŠ”ê°€
- Answer Faithfulness (AF, ì‘ë‹µ ì¶©ì‹¤ë„) : ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ ë¬¸ì„œ ë‚´ìš©ì— ì¶©ì‹¤í•œê°€ 
- Answer Relevance (AR, ì‘ë‹µ ì ì ˆì„±) : ë‹µë³€ì´ ì§ˆë¬¸ì— ì§ì ‘ì ì´ê³  êµ¬ì²´ì ì¸ê°€


---
### 3ï¸âƒ£ PPI ë³´ì • ì ìˆ˜ ìš”ì•½ 

| í‰ê°€ëŒ€ìƒ | **CR (ë³´ì •)** | AF (ë³´ì •) | AR (ë³´ì •) | **ì¢…í•© ì ìˆ˜** | ê¸°ê³„ ì˜ˆì¸¡ í‰ê·  | **CR í¸í–¥** | **AF í¸í–¥** | **AR í¸í–¥** | ì´ ìƒ˜í”Œ ìˆ˜ |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
"""

    # ê° ì¶•ë³„ í¸í–¥ì„ ì¶œë ¥í•˜ë„ë¡ í…Œì´ë¸” ë°ì´í„° êµ¬ì„±
    for summary in model_summaries:
        # KEY_CR ë“±ì˜ ìƒìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ summary ë”•ì…”ë„ˆë¦¬ì˜ ê°’ì„ ì•ˆì „í•˜ê²Œ ì°¸ì¡°
        cr_str = f"{summary[KEY_CR]['corrected_mean']:.2f}"
        af_str = f"{summary[KEY_AF]['corrected_mean']:.2f}"
        ar_str = f"{summary[KEY_AR]['corrected_mean']:.2f}"

        # ì¶•ë³„ í¸í–¥ (ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œ)
        cr_bias = f"{summary[KEY_CR]['applied_rectifier']:.3f}"
        af_bias = f"{summary[KEY_AF]['applied_rectifier']:.3f}"
        ar_bias = f"{summary[KEY_AR]['applied_rectifier']:.3f}"

        report_content += (
            f"| **{summary['model_name']}** "
            f"| {cr_str} "
            f"| {af_str} "
            f"| {ar_str} "
            f"| **{summary['overall']:.2f}** "
            f"| {summary[KEY_CR]['machine_mean']:.2f} "  # CR ì¶•ì˜ ê¸°ê³„ ì˜ˆì¸¡ í‰ê·  ì‚¬ìš© (ëŒ€í‘œê°’)
            f"| **{cr_bias}** "
            f"| **{af_bias}** "
            f"| **{ar_bias}** "
            f"| {summary['n']} |\n"
        )

    report_content += f"""

#### ğŸ’¡ ì ìˆ˜ ìš”ì•½ ì˜ë¯¸ ì„¤ëª…
- CR, AF, AR (ë³´ì •) : PPI ë³´ì • ë¡œì§ì„ ê±°ì³ **í¸í–¥ì´ ì œê±°ëœ** ê° ì¶•ì˜ ìµœì¢… ì„±ëŠ¥ ì¶”ì •ì¹˜. 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ì€ ì„±ëŠ¥ (0.0 ~ 1.0)
- ì¢…í•© ì ìˆ˜ : ì‹¬ì‚¬ê´€ì˜ ì˜ˆì¸¡ í‰ê· ì—ì„œ ê³¨ë“ ì…‹ ê¸°ë°˜ ì˜ˆì¸¡ í¸í–¥ì„ ì œê±°í•˜ì—¬ ê³„ì‚°ëœ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„±ëŠ¥ ì¶”ì •ì¹˜
- ì‹¬ì‚¬ê´€ ì˜ˆì¸¡ í‰ê·  : ARES ì‹¬ì‚¬ê´€ì´ ì˜ˆì¸¡í•œ ì ìˆ˜($\hat{{Y}}$)ì˜ ë‹¨ìˆœ í‰ê·  (ë³´ì • ì „ ì ìˆ˜)
- CR/AF/AR í¸í–¥ : ëª¨ë¸ì˜ ì˜ˆì¸¡ í‰ê· ($\hat{{Y}}$) - ê° ì¶•ì˜ í¸í–¥ê°’. ($\hat{{Y}} - Y$)
- ì´ ìƒ˜í”Œ ìˆ˜ : í‰ê°€ì— ì‚¬ìš©ëœ Q-C-A íŠ¸ë¦¬í”Œì˜ ì „ì²´ ê°œìˆ˜

---
### 4ï¸âƒ£ ë³´ì • ë¡œì§ ë° í•´ì„

* PPI ë³´ì • ì ìš©: PPI(Prediction-Powered Inference) ë°©ì‹ì— ë”°ë¼ ë³´ì • í‰ê·  (Corrected Mean)ì„ ì‚°ì¶œí–ˆìŠµë‹ˆë‹¤.
* ë³´ì • ë°©ë²•: ê³¨ë“  ë¼ë²¨(Gold Label) ê¸°ë°˜ì˜ ì‹¤ì œ í¸í–¥(Rectifier Mean)ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

    return report_content


def run_summary_generation_pipeline(ppi_correction_active: bool, gold_fields: Dict[str, str]):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ë¥¼ ìœ„í•´ ë¶„ì„/ì €ì¥ ë¡œì§ë§Œ ë¶„ë¦¬í•©ë‹ˆë‹¤."""

    if not ppi_correction_active:
        raise RuntimeError("PPI ë³´ì •ì„ ìœ„í•œ ê³¨ë“  ë¼ë²¨ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ë³´ê³ ì„œ ìƒì„±ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # config ëª¨ë“ˆì˜ DATA_OUT_DIR, DATA_REPORT_DIR ì°¸ì¡°
    INPUT_DIR_SUM = config.DATA_OUT_DIR
    OUTPUT_DIR_SUM = config.DATA_REPORT_DIR

    os.makedirs(OUTPUT_DIR_SUM, exist_ok=True)

    ppi_files = [
        os.path.join(INPUT_DIR_SUM, f)
        for f in os.listdir(INPUT_DIR_SUM)
        if f.endswith('.jsonl') and len(f.split('_')) >= 2
    ]

    if not ppi_files:
        print(f"[WARN] {INPUT_DIR_SUM}ì—ì„œ ë¶„ì„í•  PPI íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë³´ê³ ì„œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print(f"[INFO] ì´ {len(ppi_files)}ê°œ ëª¨ë¸ì˜ PPI íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    model_summaries = []

    for file_path in ppi_files:
        try:
            summary = analyze_ppi_file(file_path, True, gold_fields)
            if summary:
                model_summaries.append(summary)
                print(f"   [SUCCESS] ëª¨ë¸ '{summary['model_name']}' ë¶„ì„ ì™„ë£Œ.")
        except Exception as e:
            # ìœ íš¨ì„± ê²€ì¦ ì˜¤ë¥˜ ì‹œ ì˜¤ë¥˜ ë°œìƒ
            print(f"   [ERROR] ëª¨ë¸ '{os.path.basename(file_path)}' ë¶„ì„ ì‹¤íŒ¨: {e}")
            continue

    if not model_summaries:
        print("[WARN] ë¶„ì„ ê°€ëŠ¥í•œ ëª¨ë¸ ë°ì´í„°ê°€ ì—†ì–´ ë³´ê³ ì„œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    report_content = generate_summary_report(model_summaries)

    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_filename = f"summary_{timestamp}.md"
    output_path = os.path.join(OUTPUT_DIR_SUM, output_filename)

    with open(output_path, 'w', encoding='utf-8') as outfile:
        outfile.write(report_content)

    print("\n\n=============== ARES í†µê³„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ (ì¶•ë³„ í¸í–¥ ë°˜ì˜) ===============")
    print(f"**í†µê³„ ë³´ê³ ì„œ ì €ì¥ ê²½ë¡œ:** {output_path}")
    print("==========================================================")