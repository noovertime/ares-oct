# ares_batch_report_util.py

import os
import json
import time
from typing import Dict, List, Any, Tuple
from scipy.stats import binom
from scipy.optimize import brentq

# configëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì„¤ì •ëœ í™˜ê²½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
import config

# ===================================================================
# 0. ì „ì—­ ìƒìˆ˜ (ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì •ì˜ëœ ê²ƒì„ ì‚¬ìš©í•˜ê±°ë‚˜ ì¬ì •ì˜)
# ===================================================================

CI_ALPHA = 0.05  # 95% ì‹ ë¢°êµ¬ê°„ (alpha=0.05)
# PPI ë³´ì • ì‹œì—°ì„ ìœ„í•œ ê°€ìƒ ìƒìˆ˜ (ê³¨ë“  ë¼ë²¨ ì œê³µ ì‹œ ì‹¤ì œ ê°’ìœ¼ë¡œ ëŒ€ì²´ë  ì˜ˆì •)
HYPOTHETICAL_RECTIFIER_MEAN = 0.20


# ===================================================================
# 1. í†µê³„ ê³„ì‚° ìœ í‹¸ë¦¬í‹° (PPI ë¡œì§ ê¸°ë°˜)
# ===================================================================

def calculate_binomial_ci(n: int, k: int, alpha: float = 0.05) -> Tuple[float, float]:
    """
    ppi.pyì˜ binomial_iid ë¡œì§ì„ ì‚¬ìš©í•˜ì—¬ 95% ì´í•­ ì‹ ë¢°êµ¬ê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    if n == 0:
        return 0.0, 1.0

    muhat = k / n

    def invert_lower_tail(mu):
        return binom.cdf(k, n, mu) - (1 - alpha / 2)

    def invert_upper_tail(mu):
        return binom.cdf(k, n, mu) - (alpha / 2)

    if k == n:
        u = 1.0
    else:
        try:
            u = brentq(invert_upper_tail, muhat, 1.0)
        except ValueError:
            u = 1.0

    if k == 0:
        l = 0.0
    else:
        try:
            l = brentq(invert_lower_tail, 0.0, muhat)
        except ValueError:
            l = 0.0

    return l, u


def analyze_ppi_file(filepath: str) -> Dict[str, Any]:
    """
    ë‹¨ì¼ PPI íŒŒì¼ì„ ì½ì–´ PPI ë³´ì • í‰ê·  ë° ì‹ ë¢°êµ¬ê°„ì„ ê³„ì‚°í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤.
    """
    model_name_raw = os.path.basename(filepath)
    all_scores: Dict[str, List[int]] = {
        'contextrelevance': [],
        'answerfaithfulness': [],
        'answerrelevance': []
    }

    # ì…ë ¥ íŒŒì¼ëª…ì—ì„œ ëª¨ë¸ëª… ì¶”ì¶œ (ì˜ˆ: 'inputfilename_timestamp.jsonl' -> 'inputfilename')
    model_name_parts = model_name_raw.split('_')
    model_name = "_".join(model_name_parts[:-1])
    if not model_name:
        model_name = model_name_raw.replace(".jsonl", "")

    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())
                    for key in all_scores.keys():
                        if key in data:
                            all_scores[key].append(data[key])
                except json.JSONDecodeError:
                    print(f"[WARN] íŒŒì¼ {model_name_raw}ì—ì„œ JSON ë””ì½”ë”© ì˜¤ë¥˜ ë°œìƒ. ë¼ì¸ ê±´ë„ˆëœ€.")
                    continue
    except FileNotFoundError:
        print(f"[ERROR] íŒŒì¼ {filepath}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

    total_n = len(all_scores['contextrelevance'])
    if total_n == 0:
        print(f"[WARN] íŒŒì¼ {model_name}ì— ìœ íš¨í•œ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    summary = {
        'model_name': model_name,
        'n': total_n,
        'rectifier_mean': HYPOTHETICAL_RECTIFIER_MEAN
    }

    overall_corrected_scores = []

    for axis in all_scores.keys():
        scores = all_scores[axis]
        success_k = sum(scores)

        # 1. ê¸°ê³„ ì˜ˆì¸¡ í‰ê·  (tilde_theta_f)
        machine_mean = success_k / total_n

        # 2. PPI ë³´ì • í‰ê·  (theta_hat_PP = machine_mean - rectifier_mean)
        corrected_mean = max(0.0, min(1.0, machine_mean - HYPOTHETICAL_RECTIFIER_MEAN))

        # 3. ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ì´í•­ CI)
        l, u = calculate_binomial_ci(total_n, success_k)
        margin = (u - l) / 2

        summary[axis] = {
            'machine_mean': round(machine_mean, 2),
            'corrected_mean': round(corrected_mean, 2),
            'ci': round(margin, 3)
        }
        overall_corrected_scores.append(corrected_mean)

    # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ë³´ì •ëœ 3ì¶• í‰ê· )
    summary['overall'] = round(sum(overall_corrected_scores) / 3, 2)

    return summary


def generate_summary_report(model_summaries: List[Dict[str, Any]]):
    """
    ë¶„ì„ëœ ëª¨ë¸ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… Markdown í˜•ì‹ì˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """

    if not model_summaries:
        return "[WARN] ë¶„ì„í•  ëª¨ë¸ ë°ì´í„°ê°€ ì—†ì–´ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    current_time = time.strftime("%Y-%m-%d %H:%M:%S")

    # ëª¨ë¸ ì´ë¦„ ì •ë ¬ (ì¢…í•© ì ìˆ˜ê°€ ë†’ì€ ìˆœì„œë¡œ)
    model_summaries.sort(key=lambda x: x['overall'], reverse=True)

    report_content = f"""
# ğŸ§­ ARES ìë™ í‰ê°€ ê²°ê³¼ ë³´ê³ ì„œ (Prediction-Powered Inference ë³´ì •)

í”„ë¡œì íŠ¸ëª…: ARES ì‹¬ì‚¬ê´€ ë¡œì»¬ ë°°ì¹˜ í‰ê°€
í‰ê°€ í”„ë ˆì„ì›Œí¬: Stanford ARES (PPI ë³´ì • ë¡œì§ í†µí•©)
í‰ê°€ ì¼ì: {current_time}
í‰ê°€ ëŒ€ìƒ ëª¨ë¸: {', '.join([s['model_name'] for s in model_summaries])}

### 1ï¸âƒ£ í‰ê°€ ê°œìš” (PPI ë³´ì • ê¸°ë°˜)

| í‰ê°€ ì¶• | ë¯¸ì„¸ë¶€ ì„¤ëª… |
| :--- | :--- |
| **Context Relevance (CR)** | ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ ìˆëŠ”ê°€ (ë¬¸ë§¥ ì í•©ì„±) |
| **Answer Faithfulness (AF)** | ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ ë¬¸ì„œ ë‚´ìš©ì— ì¶©ì‹¤í•œê°€ (ì‘ë‹µ ì¶©ì‹¤ë„) |
| **Answer Relevance (AR)** | ë‹µë³€ì´ ì§ˆë¬¸ì— ì§ì ‘ì ì´ê³  êµ¬ì²´ì ì¸ê°€ (ì‘ë‹µ ì ì ˆì„±) |

### 2ï¸âƒ£ PPI ë³´ì • ì ìˆ˜ ë° ì‹ ë¢°êµ¬ê°„ ìš”ì•½ (95% CI)

| ëª¨ë¸ëª… | **CR (ë³´ì •)** | AF (ë³´ì •) | AR (ë³´ì •) | **ì¢…í•© ì ìˆ˜** | ê¸°ê³„ ì˜ˆì¸¡ í‰ê·  | CI ë§ˆì§„ (Â±) | ì´ ìƒ˜í”Œ ìˆ˜ |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
"""

    for summary in model_summaries:
        cr_str = f"{summary['contextrelevance']['corrected_mean']:.2f}"
        af_str = f"{summary['answerfaithfulness']['corrected_mean']:.2f}"
        ar_str = f"{summary['answerrelevance']['corrected_mean']:.2f}"
        ci_margin = f"Â±{summary['contextrelevance']['ci']:.3f}"

        report_content += (
            f"| **{summary['model_name']}** "
            f"| {cr_str} "
            f"| {af_str} "
            f"| {ar_str} "
            f"| **{summary['overall']:.2f}** "
            f"| {summary['contextrelevance']['machine_mean']:.2f} "
            f"| {ci_margin} "
            f"| {summary['n']} |\n"
        )

    report_content += f"""
---
### 3ï¸âƒ£ ë³´ì • ë¡œì§ ë° í•´ì„

* **PPI ë³´ì • ì ìš©:** PPI(Prediction-Powered Inference) ë°©ì‹ì— ë”°ë¼ **ë³´ì • í‰ê·  (Corrected Mean)**ì„ ì‚°ì¶œí–ˆìŠµë‹ˆë‹¤.
* **PPI ë¶„ì‚° ê³„ì‚° ë°©ì‹:** ARESëŠ” PPI í‰ê·  ì¶”ì •ì˜ **ì ê·¼ì  ë¶„ì‚° ê³µì‹**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë³´ê³ ì„œì˜ CI ë§ˆì§„ì€ í˜„ì¬ **ì´í•­ ì‹ ë¢°êµ¬ê°„ ê·¼ì‚¬ì¹˜**ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë©°, PPIì˜ ì—„ê²©í•œ ë¶„ì‚° ê³„ì‚°(ê¸°ê³„ ì˜ˆì¸¡ ë¶„ì‚° ë° ë³´ì •í•­ ë¶„ì‚°)ì€ ê³¨ë“  ë¼ë²¨ ì œê³µ í›„ ì¶”ê°€ í†µí•©ë  ì˜ˆì •ì…ë‹ˆë‹¤.
* **ë³´ì • ë°©ë²•:** ì´ ë³´ê³ ì„œì—ì„œëŠ” {HYPOTHETICAL_RECTIFIER_MEAN:.2f}ì˜ **ê°€ìƒ í¸í–¥(Rectifier Mean)**ì´ ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ í‰ê· ì—ì„œ ì°¨ê°ë˜ì—ˆìŠµë‹ˆë‹¤. (ê³¨ë“  ë¼ë²¨ ì œê³µ ì‹œ ì‹¤ì œ í¸í–¥ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.)
"""

    return report_content


def run_summary_generation_pipeline():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ë¥¼ ìœ„í•´ ë¶„ì„/ì €ì¥ ë¡œì§ë§Œ ë¶„ë¦¬í•©ë‹ˆë‹¤."""

    INPUT_DIR_SUM = config.DATA_OUT_DIR
    OUTPUT_DIR_SUM = config.DATA_REPORT_DIR

    os.makedirs(OUTPUT_DIR_SUM, exist_ok=True)

    # ì…ë ¥ íŒŒì¼ëª…_íƒ€ì„ìŠ¤íƒ¬í”„.jsonl í˜•ì‹ íŒŒì¼ì„ ê²€ìƒ‰
    ppi_files = [
        os.path.join(INPUT_DIR_SUM, f)
        for f in os.listdir(INPUT_DIR_SUM)
        if f.endswith('.jsonl') and len(f.split('_')) >= 2
    ]

    if not ppi_files:
        print(f"[WARN] {INPUT_DIR_SUM}ì—ì„œ ë¶„ì„í•  PPI íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë³´ê³ ì„œ ìƒì„±ì„ ê±´ë„ˆëœ•ë‹ˆë‹¤.")
        return

    print(f"[INFO] ì´ {len(ppi_files)}ê°œ ëª¨ë¸ì˜ PPI íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    model_summaries = []

    for file_path in ppi_files:
        summary = analyze_ppi_file(file_path)
        if summary:
            model_summaries.append(summary)
            print(f"   [SUCCESS] ëª¨ë¸ '{summary['model_name']}' ë¶„ì„ ì™„ë£Œ.")

    if not model_summaries:
        print("[WARN] ë¶„ì„ ê°€ëŠ¥í•œ ëª¨ë¸ ë°ì´í„°ê°€ ì—†ì–´ ë³´ê³ ì„œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    report_content = generate_summary_report(model_summaries)

    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_filename = f"summary_report_ppi_{timestamp}.md"
    output_path = os.path.join(OUTPUT_DIR_SUM, output_filename)

    with open(output_path, 'w', encoding='utf-8') as outfile:
        outfile.write(report_content)

    print("\n\n=============== ARES í†µê³„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ ===============")
    print(f"**í†µê³„ ë³´ê³ ì„œ ì €ì¥ ê²½ë¡œ:** {output_path}")
    print("==========================================================")

# run_summary_generation_pipeline í•¨ìˆ˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ í˜¸ì¶œë©ë‹ˆë‹¤.