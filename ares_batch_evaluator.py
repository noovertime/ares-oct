import os
import json
import time
import numpy as np
from typing import Dict, List, Any, Tuple # <-- Tuple ì¶”ê°€
from scipy.stats import binom, norm
from scipy.optimize import brentq


# ===================================================================
# 0. ì „ì—­ ìƒìˆ˜ ë° ì„¤ì •
# ===================================================================

INPUT_DIR = "./out"  # PPI íŒŒì¼ (report_*.jsonl)ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
OUTPUT_DIR = "./report"  # ìµœì¢… í†µê³„ ë³´ê³ ì„œê°€ ì €ì¥ë  ë””ë ‰í† ë¦¬
CI_ALPHA = 0.05  # 95% ì‹ ë¢°êµ¬ê°„ (alpha=0.05)


# ===================================================================
# 1. í†µê³„ ê³„ì‚° ìœ í‹¸ë¦¬í‹° (PPI ë¡œì§ ê¸°ë°˜)
# ===================================================================
def calculate_binomial_ci(n: int, k: int, alpha: float = 0.05) -> tuple[float, float]:
    """
    ppi.pyì˜ binomial_iid ë¡œì§ì„ ì‚¬ìš©í•˜ì—¬ 95% ì´í•­ ì‹ ë¢°êµ¬ê°„ (Clopper-Pearson ê·¼ì‚¬)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        n (int): ì´ ì‹œí–‰ íšŸìˆ˜ (Total Samples)
        k (int): ì„±ê³µ íšŸìˆ˜ (Success Count)
        alpha (float): ìœ ì˜ ìˆ˜ì¤€ (ê¸°ë³¸ê°’ 0.05 for 95% CI)

    Returns:
        Tuple[float, float]: (í•˜í•œ, ìƒí•œ)
    """
    if n == 0:
        return 0.0, 1.0  # ìƒ˜í”Œ ì—†ìœ¼ë©´ ì‹ ë¢°êµ¬ê°„ ì •ì˜ ë¶ˆê°€ëŠ¥

    # muhat (ê´€ì¸¡ëœ ì„±ê³µë¥ )
    muhat = k / n

    # í•˜í•œ(l) ê³„ì‚°ì„ ìœ„í•œ í•¨ìˆ˜: invert_lower_tail
    # (ppi.pyì˜ invert_lower_tail ë¡œì§)
    def invert_lower_tail(mu):
        return binom.cdf(k, n, mu) - (1 - alpha / 2)

    # ìƒí•œ(u) ê³„ì‚°ì„ ìœ„í•œ í•¨ìˆ˜: invert_upper_tail
    # (ppi.pyì˜ invert_upper_tail ë¡œì§)
    def invert_upper_tail(mu):
        return binom.cdf(k, n, mu) - (alpha / 2)

    # 1. ìƒí•œ (u) ê³„ì‚°
    # k == n (ëª¨ë‘ ì„±ê³µ)ì´ë©´ ìƒí•œì€ 1.0
    if k == n:
        u = 1.0
    else:
        # brentqë¥¼ ì‚¬ìš©í•˜ì—¬ [muhat, 1.0] ë²”ìœ„ì—ì„œ ê·¼ì„ ì°¾ìŠµë‹ˆë‹¤.
        try:
            u = brentq(invert_upper_tail, muhat, 1.0)
        except ValueError:
            u = 1.0

            # 2. í•˜í•œ (l) ê³„ì‚°
    # k == 0 (ëª¨ë‘ ì‹¤íŒ¨)ì´ë©´ í•˜í•œì€ 0.0
    if k == 0:
        l = 0.0
    else:
        # brentqë¥¼ ì‚¬ìš©í•˜ì—¬ [0.0, muhat] ë²”ìœ„ì—ì„œ ê·¼ì„ ì°¾ìŠµë‹ˆë‹¤.
        try:
            l = brentq(invert_lower_tail, 0.0, muhat)
        except ValueError:
            l = 0.0

    return l, u



def analyze_ppi_file(filepath: str) -> Dict[str, Any]:
    """
    ë‹¨ì¼ PPI íŒŒì¼ì„ ì½ì–´ CR, AF, ARì˜ í‰ê·  ë° ì‹ ë¢°êµ¬ê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    model_name_raw = os.path.basename(filepath)
    all_scores: Dict[str, List[int]] = {
        'contextrelevance': [],
        'answerfaithfulness': [],
        'answerrelevance': []
    }

    # íŒŒì¼ëª…ì—ì„œ ëª¨ë¸ëª… ì¶”ì¶œ (ì˜ˆ: 'report_gpt-rag.jsonl' -> 'gpt-rag')
    model_name = model_name_raw.replace("report_", "").replace(".jsonl", "")

    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())
                    for key in all_scores.keys():
                        if key in data:
                            all_scores[key].append(data[key])
                except json.JSONDecodeError:
                    # íŒŒì¼ëª…ê³¼ ë¼ì¸ ì •ë³´ ì¶œë ¥ ì¶”ê°€ (ë””ë²„ê¹… ìš©ì´)
                    print(f"[WARN] íŒŒì¼ {model_name_raw}ì—ì„œ JSON ë””ì½”ë”© ì˜¤ë¥˜ ë°œìƒ. ë¼ì¸ ê±´ë„ˆëœ€.")
                    continue
    except FileNotFoundError:
        print(f"[ERROR] íŒŒì¼ {filepath}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

    total_n = len(all_scores['contextrelevance'])
    if total_n == 0:
        print(f"[WARN] íŒŒì¼ {model_name}ì— ìœ íš¨í•œ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    summary = {
        'model_name': model_name,
        'n': total_n
    }

    overall_scores = []

    for axis in all_scores.keys():
        scores = all_scores[axis]
        success_k = sum(scores)

        # ì‹ ë¢°êµ¬ê°„ (í•˜í•œ, ìƒí•œ) ê³„ì‚°
        l, u = calculate_binomial_ci(total_n, success_k)

        mean_score = success_k / total_n

        # ì‹ ë¢°êµ¬ê°„ì˜ ë§ˆì§„ (Â± CI) ê³„ì‚°
        # margin = (ìƒí•œ - í•˜í•œ) / 2
        margin = (u - l) / 2

        summary[axis] = {
            'mean': round(mean_score, 2),
            'ci': round(margin, 3)  # ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼
        }
        overall_scores.append(mean_score)

    # ì¢…í•© ì ìˆ˜ ê³„ì‚° (3ì¶• í‰ê· )
    summary['overall'] = round(sum(overall_scores) / 3, 2)

    return summary


# ===================================================================
# 2. ë³´ê³ ì„œ ìƒì„± ë° ì¶œë ¥
# ===================================================================

def generate_summary_report(model_summaries: List[Dict[str, Any]]):
    # (ë‚´ìš© ìœ ì§€)
    """
    ë¶„ì„ëœ ëª¨ë¸ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… Markdown í˜•ì‹ì˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """

    if not model_summaries:
        return "[WARN] ë¶„ì„í•  ëª¨ë¸ ë°ì´í„°ê°€ ì—†ì–´ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    current_time = time.strftime("%Y-%m-%d %H:%M:%S")
    report_name = "RAG ìë™ í‰ê°€ ê²°ê³¼ (ARES PPI ìš”ì•½)"

    # ëª¨ë¸ ì´ë¦„ ì •ë ¬ (ë³´ê³ ì„œ ê°€ë…ì„± í–¥ìƒ)
    model_summaries.sort(key=lambda x: x['overall'], reverse=True)

    # í…œí”Œë¦¿ ì‘ì„±
    report_content = f"""
# ğŸ§­ ARES ìë™ í‰ê°€ ê²°ê³¼ ë³´ê³ ì„œ (Prediction-Powered Inference ìš”ì•½)

í”„ë¡œì íŠ¸ëª…: ARES ì‹¬ì‚¬ê´€ ë¡œì»¬ ë°°ì¹˜ í‰ê°€
í‰ê°€ í”„ë ˆì„ì›Œí¬: Stanford ARES (PPI ê¸°ë°˜ ì´í•­ ì‹ ë¢°êµ¬ê°„)
í‰ê°€ ì¼ì: {current_time}
í‰ê°€ ëŒ€ìƒ ëª¨ë¸: {', '.join([s['model_name'] for s in model_summaries])}

### 1ï¸âƒ£ í‰ê°€ ê°œìš”

| í‰ê°€ ì¶• | ë¯¸ì„¸ë¶€ ì„¤ëª… |
| :--- | :--- |
| **Context Relevance (CR)** | ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ ìˆëŠ”ê°€ (ë¬¸ë§¥ ì í•©ì„±) |
| **Answer Faithfulness (AF)** | ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ ë¬¸ì„œ ë‚´ìš©ì— ì¶©ì‹¤í•œê°€ (ì‘ë‹µ ì¶©ì‹¤ë„) |
| **Answer Relevance (AR)** | ë‹µë³€ì´ ì§ˆë¬¸ì— ì§ì ‘ì ì´ê³  êµ¬ì²´ì ì¸ê°€ (ì‘ë‹µ ì ì ˆì„±) |

### 2ï¸âƒ£ ìë™ í‰ê°€ ì ìˆ˜ ë° ì‹ ë¢°êµ¬ê°„ ìš”ì•½ (95% CI)

| ëª¨ë¸ëª… | CR (Â±95% CI) | AF (Â±95% CI) | AR (Â±95% CI) | ì¢…í•© ì ìˆ˜ | ì´ ìƒ˜í”Œ ìˆ˜ |
| :--- | :--- | :--- | :--- | :--- | :--- |
"""

    # ë°ì´í„° í–‰ ì¶”ê°€
    for summary in model_summaries:
        cr_str = f"{summary['contextrelevance']['mean']:.2f} Â±{summary['contextrelevance']['ci']:.3f}"
        af_str = f"{summary['answerfaithfulness']['mean']:.2f} Â±{summary['answerfaithfulness']['ci']:.3f}"
        ar_str = f"{summary['answerrelevance']['mean']:.2f} Â±{summary['answerrelevance']['ci']:.3f}"

        report_content += (
            f"| **{summary['model_name']}** "
            f"| {cr_str} "
            f"| {af_str} "
            f"| {ar_str} "
            f"| **{summary['overall']:.2f}** "
            f"| {summary['n']} |\n"
        )

    report_content += """
---
### í•´ì„ ë° ê²°ë¡  (ìë™ ìƒì„±)

* **PPI ì ìš©:** ARESì˜ PPI(Prediction-Powered Inference) ë°©ë²•ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ, ê° ëª¨ë¸ì˜ ì„±ëŠ¥ì€ 95% ì‹ ë¢°êµ¬ê°„(CI) ë‚´ì— ì¡´ì¬í•œë‹¤ê³  í†µê³„ì ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.
* **í†µê³„ì  ì‹ ë¢°ë„:** **ì‹ ë¢°êµ¬ê°„ì´ ê²¹ì¹˜ì§€ ì•ŠëŠ” ëª¨ë¸ ê°„**ì—ëŠ” 95% ì‹ ë¢° ìˆ˜ì¤€ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ ì°¨ì´ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.
* **í‰ê°€ ì¼ê´€ì„±:** ì‹ ë¢°êµ¬ê°„ í­ì´ ì¢ì€ ëª¨ë¸ì¼ìˆ˜ë¡ í‰ê°€ ìƒ˜í”Œì— ëŒ€í•œ ì˜ˆì¸¡ ì¼ê´€ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
"""

    return report_content


# ===================================================================
# 3. ë©”ì¸ ì‹¤í–‰ ë¡œì§
# ===================================================================

def run_summary_generation():
    """
    ë©”ì¸ í•¨ìˆ˜: ./out ë””ë ‰í† ë¦¬ì˜ PPI íŒŒì¼ì„ ë¶„ì„í•˜ê³  ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print(f"\n>> ARES í†µê³„ ë³´ê³ ì„œ ìƒì„± ì‹œì‘")

    # 1. ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    if not os.path.isdir(INPUT_DIR):
        print(f"[FATAL] ì…ë ¥ ë””ë ‰í† ë¦¬ {INPUT_DIR}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PPI íŒŒì¼ ìƒì„± ë‹¨ê³„ë¥¼ ë¨¼ì € ì™„ë£Œí•˜ì„¸ìš”.")
        return

    # 2. ì…ë ¥ PPI íŒŒì¼ ëª©ë¡ ê²€ìƒ‰
    ppi_files = [
        os.path.join(INPUT_DIR, f)
        for f in os.listdir(INPUT_DIR)
        if f.endswith('.jsonl') and f.startswith('report_')
    ]

    if not ppi_files:
        print(f"[WARN] {INPUT_DIR} ë””ë ‰í† ë¦¬ì—ì„œ ë¶„ì„í•  'report_*.jsonl' PPI íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"[INFO] ì´ {len(ppi_files)}ê°œ ëª¨ë¸ì˜ PPI íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    model_summaries = []

    # 3. íŒŒì¼ë³„ ë¶„ì„ ìˆ˜í–‰
    for file_path in ppi_files:
        summary = analyze_ppi_file(file_path)
        if summary:
            model_summaries.append(summary)
            print(f"   [SUCCESS] ëª¨ë¸ '{summary['model_name']}' ë¶„ì„ ì™„ë£Œ (ìƒ˜í”Œ ìˆ˜: {summary['n']}ê°œ).")

    if not model_summaries:
        print("[WARN] ë¶„ì„ ê°€ëŠ¥í•œ ëª¨ë¸ ë°ì´í„°ê°€ ì—†ì–´ ë³´ê³ ì„œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    # 4. ìµœì¢… ë³´ê³ ì„œ ìƒì„±
    report_content = generate_summary_report(model_summaries)

    # 5. íŒŒì¼ ì €ì¥
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_filename = f"summary_report_{timestamp}.md"
    output_path = os.path.join(OUTPUT_DIR, output_filename)

    with open(output_path, 'w', encoding='utf-8') as outfile:
        outfile.write(report_content)

    print("\n\n=============== ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ ===============")
    print(f"ë¶„ì„ëœ ëª¨ë¸ ìˆ˜: {len(model_summaries)}ê°œ")
    print(f"**í†µê³„ ë³´ê³ ì„œ ì €ì¥ ê²½ë¡œ:** {output_path}")
    print("==============================================")


if __name__ == "__main__":
    run_summary_generation()